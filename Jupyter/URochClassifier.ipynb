{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b80d94da-8471-4b9e-815a-658170df3fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: natsort in c:\\users\\13523\\venvs\\lab\\lib\\site-packages (8.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "626d2532-5601-41fe-a688-6b3b752d1436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\_manifest_index_only.csv\n",
      "   piece_index    piece folder_instr category  track instrument   ext  \\\n",
      "0           01  Jupiter        vn_vc    AuMix    NaN      vn_vc  .wav   \n",
      "1           01  Jupiter        vn_vc    AuSep    1.0       None  .wav   \n",
      "2           01  Jupiter        vn_vc    AuSep    2.0       None  .wav   \n",
      "3           01  Jupiter        vn_vc      F0s    1.0       None  .txt   \n",
      "4           01  Jupiter        vn_vc      F0s    2.0       None  .txt   \n",
      "5           01  Jupiter        vn_vc    Notes    1.0       None  .txt   \n",
      "6           01  Jupiter        vn_vc    Notes    2.0       None  .txt   \n",
      "7           01  Jupiter        vn_vc    Score    NaN      vn_vc  .mid   \n",
      "8           01  Jupiter        vn_vc    Score    NaN      vn_vc  .pdf   \n",
      "9           01  Jupiter        vn_vc    Video    NaN      vn_vc  .mp4   \n",
      "10          02   Sonata        vn_vn    AuMix    NaN      vn_vn  .wav   \n",
      "11          02   Sonata        vn_vn    AuSep    1.0       None  .wav   \n",
      "12          02   Sonata        vn_vn    AuSep    2.0       None  .wav   \n",
      "13          02   Sonata        vn_vn      F0s    1.0       None  .txt   \n",
      "14          02   Sonata        vn_vn      F0s    2.0       None  .txt   \n",
      "15          02   Sonata        vn_vn    Notes    1.0       None  .txt   \n",
      "16          02   Sonata        vn_vn    Notes    2.0       None  .txt   \n",
      "17          02   Sonata        vn_vn    Score    NaN      vn_vn  .mid   \n",
      "18          02   Sonata        vn_vn    Score    NaN      vn_vn  .pdf   \n",
      "19          02   Sonata        vn_vn    Video    NaN      vn_vn  .mp4   \n",
      "\n",
      "                                                 path            folder  \n",
      "0   C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\01...  01_Jupiter_vn_vc  \n",
      "1   C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\01...  01_Jupiter_vn_vc  \n",
      "2   C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\01...  01_Jupiter_vn_vc  \n",
      "3   C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\01...  01_Jupiter_vn_vc  \n",
      "4   C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\01...  01_Jupiter_vn_vc  \n",
      "5   C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\01...  01_Jupiter_vn_vc  \n",
      "6   C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\01...  01_Jupiter_vn_vc  \n",
      "7   C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\01...  01_Jupiter_vn_vc  \n",
      "8   C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\01...  01_Jupiter_vn_vc  \n",
      "9   C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\01...  01_Jupiter_vn_vc  \n",
      "10  C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\02...   02_Sonata_vn_vn  \n",
      "11  C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\02...   02_Sonata_vn_vn  \n",
      "12  C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\02...   02_Sonata_vn_vn  \n",
      "13  C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\02...   02_Sonata_vn_vn  \n",
      "14  C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\02...   02_Sonata_vn_vn  \n",
      "15  C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\02...   02_Sonata_vn_vn  \n",
      "16  C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\02...   02_Sonata_vn_vn  \n",
      "17  C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\02...   02_Sonata_vn_vn  \n",
      "18  C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\02...   02_Sonata_vn_vn  \n",
      "19  C:\\Users\\13523\\Desktop\\URochDataset_trimmed\\02...   02_Sonata_vn_vn  \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from natsort import natsorted  # pip install natsort\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "ROOT = Path(r\"C:\\Users\\13523\\Desktop\\URochDataset_trimmed\")\n",
    "\n",
    "# piece metadata from folder name only (authoritative)\n",
    "FOLDER_RE = re.compile(r\"^(?P<idx>\\d+)[ _-]+(?P<piece>[A-Za-z0-9]+)_(?P<instr>.+)$\")\n",
    "def parse_folder_meta(folder: Path):\n",
    "    m = FOLDER_RE.match(folder.name)\n",
    "    if not m:\n",
    "        return {\"piece_index\": None, \"piece\": folder.name, \"folder_instr\": None}\n",
    "    d = m.groupdict()\n",
    "    return {\"piece_index\": d[\"idx\"].zfill(2), \"piece\": d[\"piece\"].title(), \"folder_instr\": d[\"instr\"].lower()}\n",
    "\n",
    "def list_clean_files(folder: Path):\n",
    "    \"\"\"List files, drop macOS resource forks (._*).\"\"\"\n",
    "    fs = [p for p in folder.iterdir() if p.is_file()]\n",
    "    fs = [p for p in fs if not p.name.startswith(\"._\")]\n",
    "    return natsorted(fs, key=lambda p: p.name.lower())\n",
    "\n",
    "def block_indices(files):\n",
    "    \"\"\"Return indices for category blocks using only startswith checks.\"\"\"\n",
    "    names = [f.name for f in files]\n",
    "    idx = {\n",
    "        \"AuMix\":   [i for i,n in enumerate(names) if n.startswith(\"AuMix_\")],\n",
    "        \"AuSep\":   [i for i,n in enumerate(names) if n.startswith(\"AuSep_\")],\n",
    "        \"F0s\":     [i for i,n in enumerate(names) if n.startswith(\"F0s_\")],\n",
    "        \"Notes\":   [i for i,n in enumerate(names) if n.startswith(\"Notes_\")],\n",
    "        \"Score\":   [i for i,n in enumerate(names) if n.startswith(\"Sco_\")],\n",
    "        \"Video\":   [i for i,n in enumerate(names) if n.startswith(\"Vid_\")],\n",
    "    }\n",
    "    return idx\n",
    "\n",
    "def index_piece_by_position(folder: Path):\n",
    "    meta  = parse_folder_meta(folder)\n",
    "    files = list_clean_files(folder)\n",
    "    idx   = block_indices(files)\n",
    "\n",
    "    rows = []\n",
    "    # infer tracks by counting AuSep files\n",
    "    n_tracks = len(idx[\"AuSep\"])\n",
    "\n",
    "    # AuMix (0 or 1)\n",
    "    for i in idx[\"AuMix\"]:\n",
    "        rows.append({**meta, \"category\":\"AuMix\", \"track\":None,\n",
    "                     \"instrument\": meta[\"folder_instr\"], \"ext\":files[i].suffix.lower(),\n",
    "                     \"path\": str(files[i].resolve()), \"folder\": folder.name})\n",
    "\n",
    "    # Per-track blocks (use only index order; no parsing)\n",
    "    for t, i in enumerate(idx[\"AuSep\"], start=1):\n",
    "        rows.append({**meta, \"category\":\"AuSep\", \"track\":t,\n",
    "                     \"instrument\": None, \"ext\":files[i].suffix.lower(),\n",
    "                     \"path\": str(files[i].resolve()), \"folder\": folder.name})\n",
    "\n",
    "    for t, i in enumerate(idx[\"F0s\"], start=1):\n",
    "        rows.append({**meta, \"category\":\"F0s\", \"track\":t,\n",
    "                     \"instrument\": None, \"ext\":files[i].suffix.lower(),\n",
    "                     \"path\": str(files[i].resolve()), \"folder\": folder.name})\n",
    "\n",
    "    for t, i in enumerate(idx[\"Notes\"], start=1):\n",
    "        rows.append({**meta, \"category\":\"Notes\", \"track\":t,\n",
    "                     \"instrument\": None, \"ext\":files[i].suffix.lower(),\n",
    "                     \"path\": str(files[i].resolve()), \"folder\": folder.name})\n",
    "\n",
    "    # Score (mid/pdf, order doesn’t matter)\n",
    "    for i in idx[\"Score\"]:\n",
    "        rows.append({**meta, \"category\":\"Score\", \"track\":None,\n",
    "                     \"instrument\": meta[\"folder_instr\"], \"ext\":files[i].suffix.lower(),\n",
    "                     \"path\": str(files[i].resolve()), \"folder\": folder.name})\n",
    "\n",
    "    # Video (0 or 1)\n",
    "    for i in idx[\"Video\"]:\n",
    "        rows.append({**meta, \"category\":\"Video\", \"track\":None,\n",
    "                     \"instrument\": meta[\"folder_instr\"], \"ext\":files[i].suffix.lower(),\n",
    "                     \"path\": str(files[i].resolve()), \"folder\": folder.name})\n",
    "\n",
    "    # Quick sanity checks (optional)\n",
    "    if n_tracks and (len(idx[\"F0s\"]) not in (0, n_tracks) or len(idx[\"Notes\"]) not in (0, n_tracks)):\n",
    "        print(f\"[WARN] {folder.name}: tracks inferred={n_tracks} \"\n",
    "              f\"but F0s={len(idx['F0s'])}, Notes={len(idx['Notes'])}\")\n",
    "\n",
    "    return rows\n",
    "\n",
    "def build_manifest(root: Path):\n",
    "    all_rows = []\n",
    "    for fol in natsorted([d for d in root.iterdir() if d.is_dir()], key=lambda p: p.name.lower()):\n",
    "        all_rows.extend(index_piece_by_position(fol))\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    if not df.empty:\n",
    "        df = df.sort_values([\"piece_index\",\"category\",\"track\"], na_position=\"last\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Run\n",
    "df = build_manifest(ROOT)\n",
    "out_csv = ROOT / \"_manifest_index_only.csv\"\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(\"[saved]\", out_csv)\n",
    "print(df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42de9bd-64b3-4426-af6b-88eb7c9d57bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#midi conversion\n",
    "import tempfile, subprrocess\n",
    "import soundfile as sf\n",
    "import pretty_midi\n",
    "\n",
    "def render_midi_with_fluidsynth(midi_path, output_dir, soundfont_path, sr=32000, gain=0.5):\n",
    "    midi_path = Path(midi_path); output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    midi = pretty_midi.PrettyMIDI(str(midi_path))\n",
    "    stems = {}\n",
    "    for i, inst in enumerate(midi.instruments):\n",
    "        pm = pretty_midi.PrettyMIDI()\n",
    "        pm.instruments.append(inst)\n",
    "        tmp = tempfile.NamedTemporaryFile(suffix=\".mid\", delete=False)\n",
    "        pm.write(tmp.name)\n",
    "        stem_name = (inst.name or f\"program{inst.program}\").replace(\" \",\"_\").replace(\"/\",\"_\")\n",
    "        out_wav = output_dir / f\"{midi_path.stem}_inst{i}_{stem_name}.wav\" #output name\n",
    "        subprocess.run([\n",
    "            \"fluidsynth\",\"-ni\", soundfont_path, tmp.name,\n",
    "            \"-F\", str(out_wav), \"-r\", str(sr), \"-g\", str(gain)\n",
    "        ], check=True, capture_output=True)\n",
    "        audio, _ = sf.rad(out_wav)\n",
    "        stems[stem_name] = audio.astype(np.float32)\n",
    "        tmp.close()\n",
    "        Path(tmp.name).unlink(missing_ok=True)\n",
    "    #mix\n",
    "    max_len = max(len(x) for x in stems.values())\n",
    "    mix = np.zeros(max_len, dtype=np.float32)\n",
    "    for x in stems.values():\n",
    "        if len(x) < max_len:\n",
    "            x = np.pad(x, (0, max_len-len(x)))\n",
    "        mix += x\n",
    "    mix = mix / max(1e-6, np.max(np.abs(mix)))\n",
    "    mix_path = output_dir / f\"{midi_path.stem}_mixture.wav\"\n",
    "    sf.write(mix_path, mix, sr)\n",
    "    return mix_path, stems\n",
    "\n",
    "def render_midi_with_pretty_midi(midi_path, output_dir, sr=32000):\n",
    "    midi_path = Path(midi_path); output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    midi = pretty_midi.PrettyMIDI(str(midi_path))\n",
    "    stems = {}\n",
    "    longest = 0\n",
    "    for i, inst in enumerate(midi.instruments):\n",
    "        audio = inst.synthesize(fs=sr).astype(np.float32)\n",
    "        name = (inst.name or f\"program{inst.program}\").replace(\" \",\"_\")\n",
    "        sf.write(output_dir / f\"{midi_path.stem}_inst{i}_{name}.wav\", audio, sr)\n",
    "        stems[name] = audio; longest = max(longest, len(audio))\n",
    "    mix = np.zeros(longest, dtype=np.float32)\n",
    "    for a in stems.values():\n",
    "        if len(a) < longest:\n",
    "            a = np.pad(a, (0, longest-len(a)))\n",
    "        mix += a\n",
    "    mix = mix / max(1e-6, np.max(np.abs(mix)))\n",
    "    mix_path = output_dir / f\"{midi_path.stem}_mixture.wav\"\n",
    "    sf.write(mix_path, mix, sr)\n",
    "    return mix_path, stems\n",
    "\n",
    "def batch_render_midis(midi_dir, output_dir, method='fluidsynth', soundfont_path='/usr/share/sounds/sf2/FluidR3_GM.sf2', sr=32000):\n",
    "    midi_dir = Path(midi_dir)\n",
    "    files = list(midi_dir.glob(\"*.mid\")) + list(midi_dir.glob(\"*.midi\"))\n",
    "    print(f\"Found {len(files)} MIDI files\")\n",
    "    for m in sorted(files):\n",
    "        print(f\"Rendering {m.name}…\")\n",
    "        try:\n",
    "            if method==\"fluidsynth\":\n",
    "                render_midi_with_fluidsynth(m, output_dir, soundfont_path, sr=sr)\n",
    "            else:\n",
    "                render_midi_with_pretty_midi(m, output_dir, sr=sr)\n",
    "        except Exception as e:\n",
    "            print(\"  ✗ Failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75722f93-b81b-44db-a285-15272d069436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio proccessing\n",
    "import librosa\n",
    "import pyloudnorm as pyln\n",
    "import torch, torchaudio\n",
    "eps = 1e-10\n",
    "\n",
    "def ensure_mono(wav: torch.Tensor) -> torch.Tensor: #wav: (ch, n)\n",
    "    if wav.dim() == 1:\n",
    "        return wav.unsqueeze(0)\n",
    "    if wav.shape[0] > 1:\n",
    "        return wav.mean(dim=0, keepdim=True)\n",
    "    return wav\n",
    "\n",
    "def loudness_normalize_lufs(wav: torch.Tensor, sr: int, target_lufs =- 23.0) -> torch.Tensor:\n",
    "    x = wav.squeeze(0).cpu().numpy().astype(np.float32)\n",
    "    meter = pyln.Meter(sr)\n",
    "    try:\n",
    "        lufs = meter.integrated_loudness(x)\n",
    "        y = pyln.normalize.loudness(x, lufs, target_lufs)\n",
    "    except ValueError:\n",
    "        y = x\n",
    "    y = np.clip(y, -1.0, 1,0)\n",
    "    return torch.from_numpy(y).unsqueeze(0)\n",
    "\n",
    "def preprocess_audio(audio_path, target_sr=32000, target_lufs=- 23.0, trim_db =- 40):\n",
    "    wav, sr = torchaudio.load(str(audio_path)) #load audio + sampling rate\n",
    "    if sr!= target_sr:\n",
    "        wav = torchaudio.functional.resample(wav,sr, target_sr); sr = target_sr\n",
    "    wav = ensure_mono(wav)\n",
    "    wav = loudness_normalize_lufs(wav, sr, targget_lufs)\n",
    "    wav = trim_silence(wav, sr, threshold_db=trim_db)\n",
    "    return wav, sr\n",
    "\n",
    "def trim_silence(wav: torch.Tensor, sr: int, threshold_db =- 40, frame_length = 2048, hop_length = 512):\n",
    "    x = wav.squeeze(0).cpu().numpy().astype(np.float32)\n",
    "    rms = librosa.feature.rms(y=x, frame_length=frame_length, hop_length=hop_length)[0]\n",
    "    rms_db = librosa.amplitude_to_db(rms, ref=np.max+eps)\n",
    "    voiced = rms_db > threshold_db\n",
    "    if not voiced.any(): #return wav if its empty\n",
    "        return wav\n",
    "    idx = np.where(voiced)[0]\n",
    "    start = max(0, idx[0]-5): end = min(len(rms), idx[-1]+5)\n",
    "    start_s = start*hop_length; end_s = min(len(x), end*hop_length)\n",
    "    y = x[start_s:end_s]\n",
    "    return torch.from_numpy(y).unsqueeze(0)\n",
    "\n",
    "def make_mel_transform(sr=32000, n_fft=2048, hop=512, n_mels=128, fmin=55, fmax=8000):\n",
    "    mel = torchaudio.transforms.MelSpectrogram(\n",
    "        ample_rate=sr, n_fft=n_fft, hop_length=hop, win_length=n_fft,\n",
    "        n_mels=n_mels, f_min=fmin, f_max=fmax, window_fn=torch.hann_window,\n",
    "        power=2.0, normalized=False, center=True, pad_mode=\"reflect\",\n",
    "        mel_scale=\"htk\", norm=\"slaney\"\n",
    "    )\n",
    "    to_db = torchaudio.transforms.AmplitudeToDB(stype=\"power\", top_db=80)\n",
    "    return mel, to_db\n",
    "\n",
    "def crop_or_pad_spec(spec: torch.Tensor, target_frames: int) -> torch.Tensor:\n",
    "    F, T = spec.shape\n",
    "    if T == target_frames: return spec\n",
    "    if T > target_frames:\n",
    "        s = (T - target_frames) // 2\n",
    "        return spec[:, s:s+target_frame]\n",
    "    pad = target_frames - T\n",
    "    left = pad // 2; right = pad - left\n",
    "    return torch.nn.functional.pad(spec, (left, right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4075609-7c79-42ee-96eb-bb571b95c48c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
